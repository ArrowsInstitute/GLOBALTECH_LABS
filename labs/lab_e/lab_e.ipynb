{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab E: コンピュータ・ビジョン入門\n",
    "\n",
    "このノートブックでは、Racecarのカメラを利用して色を判別することで物体を識別し、その中心と面積を抽出する方法を学びます。\n",
    "\n",
    "このノートブック全体を通して **<font style=\"color:red\">太い赤字で書かれた文章</font>** は、実行する前にその下のコードブロックを編集して正しいコードを書く必要があります。\n",
    "\n",
    "## 目次\n",
    "1. [はじめに](#GettingStarted)\n",
    "1. [写真の撮影](#TakingPhotos)\n",
    "1. [カラーフォーマット](#ColorFormats)\n",
    "1. [マスク](#Masks)\n",
    "1. [輪郭の検出](#FindingContours)\n",
    "1. [輪郭の中心](#ContourCenter)\n",
    "1. [輪郭の面積](#ContourArea)\n",
    "1. [数値処理](#ProcessingNumericValues)\n",
    "1. [比例制御](#ProportionalControl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"GettingStarted\"></a>\n",
    "## 1. はじめに\n",
    "\n",
    "**<font style=\"color:red\">もしシミュレータを利用して開発を進める場合は、 `isSimulation` を `True` に設定します </font>**。 実際のマシンを利用する場合は、 `isSimulation` を `False` のままにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 必要に応じてisSimulationを更新する\n",
    "isSimulation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Pythonライブラリ(`cv`, `numpy`, など)や、Racecarライブラリ(`racecar_core`)など、このノートブックの実行に必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonライブラリのインポート\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from nptyping import NDArray\n",
    "from typing import Any, Tuple, List, Optional\n",
    "\n",
    "# Racecarライブラリのインポート\n",
    "import sys\n",
    "sys.path.append(\"../../library\")\n",
    "import racecar_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の関数や機能はこのノートブックでの開発を補助するものです。\n",
    "実行しておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image: NDArray) -> None:\n",
    "    \"\"\"\n",
    "    Jupyter Notebookにカラー画像を表示します。\n",
    "    \"\"\"\n",
    "    plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def draw_contour(\n",
    "    image: NDArray,\n",
    "    contour: NDArray,\n",
    "    color: Tuple[int, int, int] = (0, 255, 0)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    指定された画像に輪郭を描画する。\n",
    "\n",
    "    Args:\n",
    "        image: 輪郭を描画する画像\n",
    "        contour: 画像に描画する輪郭\n",
    "        color: BGR形式でして逸された輪郭を描画する色\n",
    "    \"\"\"\n",
    "    cv.drawContours(image, [contour], 0, color, 3)\n",
    "\n",
    "    \n",
    "def draw_circle(\n",
    "    color_image: NDArray[(Any, Any, 3), np.uint8],\n",
    "    center: Tuple[int, int],\n",
    "    color: Tuple[int, int, int] = (0, 255, 255),\n",
    "    radius: int = 6,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    指定された画像に円を描く\n",
    "\n",
    "    Args:\n",
    "        color_image: 輪郭を描画する色画像\n",
    "        center: 画像の中心ピクセル (行, 列)\n",
    "        color: BGR形式で指定された円を描く色\n",
    "        radius: ピクセル単位の円の半径\n",
    "    \"\"\"\n",
    "    # cv.circle は(列, 行)の形式で円の中心を指定します\n",
    "    cv.circle(color_image, (center[1], center[0]), radius, color, -1)\n",
    "\n",
    "    \n",
    "def show_color_bgr(blue: int, green: int, red: int) -> None:\n",
    "    \"\"\"\n",
    "    BGR形式で指定された色を表示する\n",
    "    \"\"\"\n",
    "    rectangle = plt.Rectangle((0,0), 50, 50, fc=(red/255, green/255, blue/255))\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_color_hsv(hue: int, saturation: int, value: int) -> None:\n",
    "    \"\"\"\n",
    "    HSV形式で指定された色を表示する\n",
    "    \"\"\"\n",
    "    # HSVからBGR形式に変換する\n",
    "    hsv = np.array([[[hue, saturation, value]]], np.uint8)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    show_color_bgr(bgr[0][0][0], bgr[0][0][1], bgr[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、Racecarオブジェクトを作成します。このステップで失敗した場合は`isSimulation` が正しい値であることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Racecar オブジェクトの作成\n",
    "rc = racecar_core.create_racecar(isSimulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TakingPhotos\"></a>\n",
    "## 2. 写真の撮影\n",
    "\n",
    "Jupyter Notebookでは、`rc.camera.get_color_image_async()` を利用して車のカメラで写真を撮ることができます。Jupyter Notebookではなく、実機側で写真を撮影する場合は、`rc.camera.get_color_image()` を使う必要があります。\n",
    "\n",
    "Racecarが今現在何を見ているのかを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 写真を撮影し画面に表示する\n",
    "image = rc.camera.get_color_image_async()\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カラー画像は3次元のnumpy配列として格納される: \n",
    "\n",
    "* **0次元目**: ピクセル行、上から下へのインデックス\n",
    "* **1次元目**: ピクセル行、左から右へのインデックス\n",
    "* **2次元目**: ピクセルの色値。青、緑、赤の順で、それぞれ0(色が全くない)から255(その色の最大値)まである\n",
    "\n",
    "画像の真ん中のピクセルの色を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 中心の行と列を計算する\n",
    "row = rc.camera.get_height() // 2\n",
    "col = rc.camera.get_width() // 2\n",
    "\n",
    "# 青、緑、赤の各色の値を抽出して表示する\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# 同じ色を画面に表示する\n",
    "show_color_bgr(blue, green, red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">次のコードブロックの `row` と `col` を更新して、上から2/3、右から1/4のピクセルを表示する</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Part 1: 希望の行と列を計算する \n",
    "row = \n",
    "col = \n",
    "\n",
    "# 青、緑、赤の各色の値を抽出して表示する\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# 同じ色を画面に表示する\n",
    "show_color_bgr(blue, green, red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ColorFormats\"></a>\n",
    "## 3. カラーフォーマット\n",
    "カメラで撮影された画像はデフォルトでは、青・緑・赤（BGR）形式で保存されます。しかし、色情報に基づいて物体を認識する場合は、各チャンネルがいかに対応する、色相・彩度・値（HSV）フォーマットを使用するほうがはるかに簡単です:\n",
    "\n",
    "* **色相(Hue)** (0 ~ 180): カラーホイール上で赤-橙-黄-緑-青-紫-赤の順に並んだ色\n",
    "* **彩度(Saturation)** (0 ~ 255): 色に加えられる白の量。0は純粋な白で、255は白を加えない純粋な色\n",
    "* **値(Value)** (0 ~ 255): 色に加えられる黒の量。0は純粋な黒で、255は黒を加えない純粋な色\n",
    "\n",
    "彩度と値は照明のあたり方によって変化するが、色相は照明に関係なくほとんど変わりません。検出しようとしている物体の色相に注目する事で、異なる照明環境でもその物体を見つける事ができます。\n",
    "\n",
    "次のウィジェットを利用することで、BGRとHSVフォーマットの様々な色を試す事ができます。  **<font style=\"color:red\">両方のフォーマットで、次の色を生成する値を見つけてください: オレンジ、ピンク、濃い緑、黄色、灰色</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BGR color\n",
    "widgets.interact(show_color_bgr,\n",
    "                 blue=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "                 green=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "                 red=widgets.IntSlider(0, 0, 255, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HSV color\n",
    "widgets.interact(show_color_hsv,\n",
    "                 hue=widgets.IntSlider(0, 0, 180, continuous_update=False),\n",
    "                 saturation=widgets.IntSlider(255, 0, 255, continuous_update=False),\n",
    "                 value=widgets.IntSlider(255, 0, 255, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Masks\"></a>\n",
    "## 4. マスク\n",
    "車の視野内の物体をその色に基づいて識別することに挑戦してみましょう。具体的には、HSVの上限と下限を定義することで、画像における特定の色の範囲に含まれる部分のみを切り出します。これを使って画像から抜き出す部分は白、抜き出さない部分は黒という特殊な画像 *マスク* を作成します。\n",
    "\n",
    "**<font style=\"color:red\">画像を受け取り、hsv_lowerとhsv_upperの間の領域のマスクを返す `get_mask` 関数を完成させましょう。</font>**  次のようなOpenCVの関数を利用してください:\n",
    "\n",
    "* [`cvtColor`](https://docs.opencv.org/4.2.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab): BGRからHSVのように、画像をある色形式から別の色形式に変換します\n",
    "* [`inRange`](https://docs.opencv.org/4.2.0/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981): 下限となる色と上限となる色に基づいて画像からマスクを作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(\n",
    "    image: NDArray[(Any, Any, 3), np.uint8],\n",
    "    hsv_lower: Tuple[int, int, int],\n",
    "    hsv_upper: Tuple[int, int, int]\n",
    ") -> NDArray[Any, Any]:\n",
    "    \"\"\"   \n",
    "    hsv_lowerとhsv_upperの間にある画像領域すべてを含むマスクを返す\n",
    "    \n",
    "    Args:\n",
    "        image: マスクのもととなるBGR形式の画像\n",
    "        hsv_lower: マスクに含めるHSV値の下限\n",
    "        hsv_upper: マスクに含めるHSV値の上限\n",
    "    \"\"\"\n",
    "    # hsv_lowerとhsv_uppperをnumpy配列に変換し、OpenCVで使えるようにする\n",
    "    hsv_lower = np.array(hsv_lower)\n",
    "    hsv_upper = np.array(hsv_upper)\n",
    "    \n",
    "    # TODO Part 2: cv.cvtColor関数を使用して、BGRカラーをHSVカラーに変換する\n",
    "    \n",
    "    # TODO Part 3: cv.inRange関数を使用して、正しい範囲の領域を協調表示する\n",
    "    \n",
    "    return _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_mask` 関数を使って画像内のコーンを分離してみましょう。車の視界の中にコーンを置いて、次のブロックで写真を撮ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = rc.camera.get_color_image_async()\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、`get_mask` 関数を使用して、コーンだけを含むマスク画像を作成します。現時点では、`hsv_lower` と `hsv_upper` はHSVの全体の値を含むので、マスクは画像全体を含むことになります。**<font style=\"color:red\">マスク画像がコーンだけを含むようになるまで、 `hsv_lower` と `hsv_upper` の値を調整してください。</font>**\n",
    "\n",
    "**ヒント:**\n",
    "\n",
    "* HSVカラーを視覚化るするのには、[カラーフォーマット](#ColorFormats) 節で利用したHSVカラーウィジェットを使います。\n",
    "* 画像を画像編集ソフト(gimp, ペイントなど)にコピーし、スポイト(カラーピッカー)ツールを使って、コーン内のピクセルのHSV値を調べてみましょう。\n",
    "* 彩度(Saturation)と値(Value)は照明によって大きく変化するが、色相はある物体に対してほぼ一定に保たれます。彩度や値には広い範囲を、色相(Hue)には狭い範囲を設定してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Part 4: マスク画像がコーンだけを含むようになるまで、hsv_lowerとhsv_uppperの値を調整する\n",
    "hsv_lower = (0, 50, 50)\n",
    "hsv_upper = (20, 255, 255)\n",
    "\n",
    "mask = get_mask(image, hsv_lower, hsv_upper)\n",
    "show_image(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このマスクは、`hsv_lower` と `hsv_upper` の間にある部分のみを残すためのフィルターとして、元画に適用する事ができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = cv.bitwise_and(image, image, mask=mask)\n",
    "show_image(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FindingContours\"></a>\n",
    "## 5. 輪郭の検出\n",
    "\n",
    "マスクができたので、マスク内の各物体の周囲に _輪郭(Contours)_ と呼ばれる輪郭線(アウトライン)を作成することができます。この輪郭線を用いて、画像内の最も大きな物体を特定し、その物体のサイズと位置を計算します。\n",
    "\n",
    "まず、OpenCVの関数 [`findContours`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0) を使って、マスク内の各物体を囲む輪郭のリストを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(mask: NDArray) -> List[NDArray]:\n",
    "    \"\"\"\n",
    "    マスク内のすべてのオブジェクトを囲む輪郭のリストを返します\n",
    "    \"\"\"\n",
    "    return cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_contours` は、 `hsv_lower` と `hsv_upper` の間に入る物体が複数存在する場合に、複数の輪郭を含むリストを返します。これは、画像内に複数のコーンがある場合や、コーンと同じような色を持つ物体がほかにもある場合に発生します。\n",
    "\n",
    "そこで、最大の輪郭を識別するための補助関数を作成してみましょう。また、この補助関数は最小サイズ(`30ピクセル` など)以下の輪郭を無視するような機能を持つ必要があります。\n",
    "\n",
    "**<font style=\"color:red\">`get_largest_contour` 関数を`min_area`より大きい最大の輪郭を返すように加筆修正してください。また、もしそのような輪郭がない場合は`None`を返すようにしてください。</font>**  輪郭に含まれるピクセル数を求めるには、OpenCVの [`contourArea`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) 関数を使用するのが良いでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_contour(contours: List[NDArray], min_area: int = 30) -> Optional[NDArray]:\n",
    "    \"\"\"\n",
    "    min_area よりも大きなサイズを持つ最大の輪郭を見つける\n",
    "\n",
    "    Args:\n",
    "        contours: 画像から検出された輪郭のリスト\n",
    "        min_area: 考慮する最小輪郭(ピクセル数)\n",
    "\n",
    "    Returns:\n",
    "        min_area より大きい輪郭がない場合はNoneを返す\n",
    "    \"\"\"\n",
    "    if len(contours) == 0:\n",
    "        # TODO Part 5: 輪郭のリストが空の場合、何を返すべきでしょうか？\n",
    "        return _____\n",
    "    \n",
    "    # TODO Part 6: min_area より大きい輪郭がない場合はNoneを返す\n",
    "\n",
    "    return _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、作成した関数を試してみましょう。次のコードブロックは`find_contours` と `get_largest_contour`を使って最大輪郭を見つけて、画像上に描画します。これで画像の一番近いコーンを囲む緑色の輪郭が表示されるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 最大の輪郭を見つける\n",
    "contours = find_contours(mask)\n",
    "largest_contour = get_largest_contour(contours)\n",
    "\n",
    "# 最大の輪郭を表示する\n",
    "image_copy = np.copy(image)\n",
    "draw_contour(image_copy, largest_contour)\n",
    "show_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ContourCenter\"></a>\n",
    "## 6. 輪郭の中心\n",
    "\n",
    "輪郭の利点の1つは、輪郭を利用して物体の中心を簡単に計算できることです。具体的には輪郭の[_モーメント(Moments)_](https://en.wikipedia.org/wiki/Image_moment)を利用します。これは輪郭内のピクセルの加重平均に相当します。モーメント$M_{ij}$は下記の式で計算することができます。\n",
    "\n",
    "```\n",
    "def moment(i, j):\n",
    "    sum = 0\n",
    "    for pixel in contour:\n",
    "        sum += pixel.x_position ** i + pixel.y_position ** j\n",
    "    return sum\n",
    "```\n",
    "\n",
    "輪郭の中心を計算するには以下の種類のモーメントを利用します:\n",
    "\n",
    "* $M_{00}$: 輪郭のピクセル数\n",
    "* $M_{10}$: 輪郭の各ピクセルが右にどれだけ離れているかの和\n",
    "* $M_{01}$: 輪郭の各ピクセルがどれだけ下にあるかの和\n",
    "\n",
    "[重心(center of mass equation)](https://en.wikipedia.org/wiki/Center_of_mass)を用いると, $\\frac{M['m10']}{M['m00']}$ で輪郭の水平方向の平均位置(列)が得られ、$\\frac{M['m01']}{M['m00']}$ で垂直方向の平均位置(行)が得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_center(contour: NDArray) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    画像から輪郭の中心を見つける\n",
    "\n",
    "    Args:\n",
    "        contour: 中心を求める輪郭\n",
    "\n",
    "    Returns:\n",
    "        輪郭の中心にあるピクセルの(行、列)、または輪郭が空の場合はNone\n",
    "    \"\"\"\n",
    "    # 輪郭のモーメントを計算するようにOpenCVを利用する\n",
    "    M = cv.moments(contour)\n",
    "\n",
    "    # 輪郭が空かどうかを確認する\n",
    "    if M[\"m00\"] <= 0:\n",
    "        return None\n",
    "\n",
    "    # 輪郭の重心を計算する\n",
    "    center_row = round(M[\"m01\"] / M[\"m00\"])\n",
    "    center_column = round(M[\"m10\"] / M[\"m00\"])\n",
    "    \n",
    "    return (center_row, center_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これがうまくいったかどうかを確認するために、この計算された重心に点を描きます。コーンの中心に黄色い点が見えるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "center = get_contour_center(largest_contour)\n",
    "\n",
    "# 輪郭の中心に円を描く\n",
    "draw_circle(image_copy, center)\n",
    "show_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ContourArea\"></a>\n",
    "## 7. 輪郭の面積\n",
    "\n",
    "`get_largest_contour` 関数を作成するとき、おそらくOpenCVの[`contourArea`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) 関数を利用したかと思います。輪郭の面積は物体がカメラからどれだけ離れているかを計算するのにも役立ちます。\n",
    "\n",
    "このセクションでは、車からの距離を変えてコーンの面積を測定します。**<font style=\"color:red\">ここまで作成した関数や例を使用して、以下のコードブロックを、写真を撮り、最大の輪郭を見つけ、輪郭の面積を表示し、輪郭のある画像を表示するように加筆修正してください。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Part 7: 次のコードブロックを更新して、写真を撮り、最大の輪郭を見つけ、輪郭の面積を表示し、輪郭のある画像を表示します。\n",
    "\n",
    "# TODO: 写真を撮る\n",
    "\n",
    "# TODO: 最大の輪郭を見つける\n",
    "\n",
    "# TODO: 最大の輪郭の面積を計算して、表示する\n",
    "\n",
    "# TODO: 輪郭が描かれた画像を上に表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font style=\"color:red\">コーンが車から次の距離にある時のコーンの輪郭面積を測定します: 40cm, 80cm, 120cm, 160cm, 200cm。測定した結果で次のコードブロックの`data`の情報を更新してください。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのフォーマット (車からコーンまでの距離 [cm], 輪郭のピクセル数)\n",
    "# TODO Part 8: 輪郭の面積をピクセル数で更新する\n",
    "data = [\n",
    "    (40, _____),\n",
    "    (80, _____),\n",
    "    (120, _____),\n",
    "    (160, _____),\n",
    "    (200, _____),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "距離とコーンの面積の関係を見るために、このデータをプロットしてみよう。**この関係はどのように表現できるでしょうか？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを散布図でプロットする\n",
    "data_t = np.transpose(data)\n",
    "plt.scatter(data_t[0], data_t[1])\n",
    "plt.title(\"Relationship between Distance and Contour Area\")\n",
    "plt.xlabel(\"Cone distance (cm)\")\n",
    "plt.ylabel(\"Contour area (pixels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ProcessingNumericValues\"></a>\n",
    "## 8. 数値処理\n",
    "\n",
    "抽象的な見方をすると、多くのロボット工学の仕事は以下のようにようやくできます:\n",
    "\n",
    "1. 1つもしくは複数のセンサー(画像、IMUデータ、LiDARスキャンなど)から生のデータを入力として受け取る\n",
    "2. これらの生データの入力を意味のある数値(輪郭中心、輪郭面積、中心距離、現在速度んど)に変換する\n",
    "3. これらの数値を使用して出力値(速度、角度など)を計算する\n",
    "4. これらの出力値をコントローラ(モーターなど)に送る\n",
    "\n",
    "前節では、ステップ2の例として、カラー画像(生データの入力)を中心点と輪郭面積(数値)にする例を2つ紹介しました。このセクションでは、ステップ3、つまりこれらの数値を出力値に変換するための2つの便利なツールを構築します。\n",
    "\n",
    "### Clamp\n",
    "出力値はある範囲に収まっているいなければならない事がよくあります。例えば、 `rc.drive.set_speed_angle()`に送られる速度と角度は$[-1, 1]$の範囲でなければなりません。*クランピング(Clamping)*とは、値を特定の範囲に強制的に押し込める事です。値が最小値より小さければ最小値を受け取り、値が最大値より大きければ最大値を受け取ります。\n",
    "\n",
    "例えば、clamp関数は以下のような出力を返すはずです:\n",
    "\n",
    "* `clamp(3, 0, 10) = 3`: $3$ は $0$ と $10$ の間の値なので、変更されません\n",
    "* `clamp(-2, 0, 10) = 0`: $-2$ は $0$ より小さいので、最小値で飽和されます\n",
    "* `clamp(11, 0, 10) = 10`: $11$ は $10$ より大きいので、最大値で飽和されます\n",
    "\n",
    "**<font style=\"color:red\">この動作を以下の`clamp`関数で実装する</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(value: float, min: float, max: float) -> float:\n",
    "    \"\"\"\n",
    "    最小値と最大値の間の値にクランプする\n",
    "\n",
    "    Args:\n",
    "        value: クランプする入力\n",
    "        min: 供される最小値\n",
    "        max: 許容される最大値\n",
    "\n",
    "    Returns:\n",
    "        minとmaxの間で飽和した値\n",
    "    \"\"\"\n",
    "    # TODO Part 9: 値が最小値と最大値の間であることを確認する\n",
    "    return _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは`clamp`関数をテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clamp関数のテスト\n",
    "assert clamp(3, 0, 10) == 3\n",
    "assert clamp(-2, 0, 10) == 0\n",
    "assert clamp(11, 0, 10) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のウィジェットを使って、様々な入力を試す事ができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "widgets.interact(clamp,\n",
    "                 value=widgets.FloatSlider(0, min=-2, max=2, step=0.1),\n",
    "                 min=widgets.fixed(-1),\n",
    "                 max=widgets.fixed(1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap Range\n",
    "\n",
    "入力された値がある範囲に収まるかどうかで動作を決めたいことはよくあります。例えば、輪郭の中心のx座標に基づいて車の角度を設定したり、震度画像の中心距離に基づいて車の速度を設定したりします。1つのアプローチは、入力可能な値の範囲から出力可能な値の範囲に入力値を*再マッピング*することです。\n",
    "\n",
    "例えば、$[0, 1]$の範囲を$[-1, 1]$に再マッピングするとします。$0$（古い最小値）は$-1$（新しい最小値）に、$0.5$（古い中点）は$0$（新しい中点）に、$1$（古い最大値）は$1$（新しい最大値）になります。\n",
    "\n",
    "範囲は必ずしも「順序通り」である必要はありません。 例えば、小さい数を大きくしたい、あるいはその逆をしたい場合もあります。 これは、例えば$[0, 10]$を$[10, 0]$にリマップするなど、新しい範囲を反転させることで実現できます。 このようなリマップは、$2$は$8$に、$0$は$10$に、$6$は$4$に、 $20$は$-10$に、$-2$は$12$になります。\n",
    "\n",
    "**<font style=\"color:red\">`remap_range`で、`val`を古い範囲から新しい範囲にリマップするコードを作成してください。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_range(\n",
    "    val: float,\n",
    "    old_min: float,\n",
    "    old_max: float,\n",
    "    new_min: float,\n",
    "    new_max: float,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    ある範囲から別の範囲に値をリマップする\n",
    "\n",
    "    Args:\n",
    "        val: リマップされる古い範囲の数値\n",
    "        old_min: 古い範囲の'下限'\n",
    "        old_max: 古い範囲の'上限'\n",
    "        new_min: 新しい範囲の'下限'\n",
    "        new_max: 新しい範囲の'上限'\n",
    "\n",
    "    Note:\n",
    "        方向を反転させるとマッピングの符号が反転します。\n",
    "        valはold_minとold_maxの間にあるとは限りません。\n",
    "    \"\"\"\n",
    "    # TODO Part 10: valを新しい範囲にリマップします\n",
    "    \n",
    "    return _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは `remap range` 関数をテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap_range関数のテスト\n",
    "assert remap_range(5, 0, 10, 0, 50) == 25\n",
    "assert remap_range(5, 0, 20, 1000, 900) == 975\n",
    "assert remap_range(2, 0, 1, -10, 10) == 30\n",
    "assert remap_range(200, 0, 640, -1, 1) == -0.375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のウィジェットを使って、様々な入力を試すことができます。  **出力$2.0$をもたらす、3つの異なる入力の組み合わせを見つけてみましょう。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interact(remap_range,\n",
    "                 val=widgets.FloatSlider(0, min=-10, max=10, step=0.1),\n",
    "                 old_min=widgets.FloatSlider(0, min=-10, max=10, step=0.1),\n",
    "                 old_max=widgets.FloatSlider(5, min=-10, max=10, step=0.1),\n",
    "                 new_min=widgets.FloatSlider(-1, min=-10, max=10, step=0.1),\n",
    "                 new_max=widgets.FloatSlider(1, min=-10, max=10, step=0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ProportionalControl\"></a>\n",
    "## 9. 比例制御\n",
    "\n",
    "ロボット工学でよくある目標は、望ましい状態を維持することです。例えば、車からコーンが常に30cm離れていたいとか、速度を1.0m/sに保ちたいとかです。現在の状態が望ましい状態と異なる場合、私たちは車のコントローラ(アクセル・ブレーキなどのスロットルや、ステアリングなど)を使って望ましい状態に向かうように制御する必要があります。\n",
    "\n",
    "定常状態を維持するもっとも簡単な方法の一つが、[proportional control](https://en.wikipedia.org/wiki/Proportional_control) です。この戦略は、現在の値と望ましい値との差に*比例*した変化を適用します。例えば、室温を20.0度に保ちたいとします。実際の温度がこの目標値と1度異なるごとに100単位の冷暖房を適用します。つまり:\n",
    "* 現在の温度が$20.0$度なら、希望する温度にいるので、$0$単位の暖房をかける\n",
    "* 現在の温度が$19.7$度なら、$30$単位の暖房をかける\n",
    "* 現在の温度が$21.7度なら、$-170$単位の暖房をかけます\n",
    "\n",
    "以下の入力を与えて `remap_range` を使うことで、比例制御の計算を行うことができます。\n",
    "* `val`: 入力変数 (例: 現在の室温)\n",
    "* `old_min`: 入力変数の潜在的な値 (例: 希望室温)\n",
    "* `old_max`: 入力変数のもう一つの潜在的な値 (例: 希望室温より1度低い室温)\n",
    "* `new_min`: 入力が`old_min`になった時の理想的な出力 (例: 暖房/冷房なし)\n",
    "* `new_max`: 入力が`old_max`になった時の理想的な出力 (例: 100単位の暖房)\n",
    "\n",
    "`min`と`max`は境界線ではないので、順番に並べる必要はありません。これらは単に線形関係を特徴づけるための2つの基準点です。\n",
    "\n",
    "**<font style=\"color:red\">`current_temp`の値を変えて試してみましょう。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_TEMP = 20\n",
    "current_temp = 29.7 # TODO: 異なる値に変更して試してみましょう\n",
    "\n",
    "# remap_rangeを使って、適用する暖房の単位あたりの出力を計算する\n",
    "heating = remap_range(current_temp, DESIRED_TEMP, DESIRED_TEMP - 1, 0, 100)\n",
    "print(f\"{heating:.1f} units of heating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力がある範囲内に収まらなければならない場合、`clamp`を使ってこの範囲を守るように強制することができます。例えば、サーモスタットが暖房または冷房を最大500単位まで適用できるとします。次のコードブロックは、`clamp`を使ってこの制限を強制します。\n",
    "\n",
    "**<font style=\"color:red\">`current_temp`が15度以下または25度以上の場合に何が起こるか見てみましょう。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clamped_heating = clamp(heating, -500, 500)\n",
    "print(f\"{clamped_heating:.1f} units of heating (after clamping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後の課題では、比例仔魚を使用して、カラー画像内のコーンの位置に基づいて前輪の角度を決定します。具体的には次のような手順で車をコーンに向けて操舵します:\n",
    "\n",
    "1. カラー画像を撮る\n",
    "2. 色に基づいて科増をマスクし、コーンと想定される最大の輪郭を特定する\n",
    "3. この輪郭の中心を見つけます\n",
    "4. 輪郭と中心が描かれたカラー画像を表示します\n",
    "5. 比例制御を使って、中心の列の位置を角度に変換します。つまり、中心から見て、コーンが左にどれだけ離れているかに比例して車は左に曲がり、コーンが右にどれだけどれだけ離れているかに比例して車は右に曲がるはずです。\n",
    "\n",
    "**<font style=\"color:red\">角度を計算するには、次のコードブロックの中で次のステップを実行します。</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Part 11: 比例制御を使用して、カラー画像内のコーンの位置に基づいて前輪の角度を決定させる\n",
    "\n",
    "# カラー画像を撮影する\n",
    "image = rc.camera.get_color_image_async()\n",
    "\n",
    "# TODO: カラーマスクと最大輪郭からコーンを見つける\n",
    "mask = get_mask(___, ___, ___)\n",
    "contours = find_contours(___)\n",
    "largest_contour = get_largest_contour(_____)\n",
    "\n",
    "# TODO: 輪郭の中心を見つけ、その座標を表示する\n",
    "center = _____\n",
    "print(\"Contour center: \", center)\n",
    "\n",
    "# 輪郭と中心が描かれた画像を表示する\n",
    "image_copy = np.copy(image)\n",
    "draw_contour(image_copy, largest_contour)\n",
    "draw_circle(image_copy, center)\n",
    "show_image(image_copy)\n",
    "\n",
    "# TODO: 輪郭の中心を使って、[-1, 1]の範囲の角度を計算し、表示する\n",
    "angle = _____\n",
    "print(\"Angle: \", angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、`lab_e.py`でカラーカメラを利用してラインフォローを行う準備ができました。皆さんの幸運を祈ります！もし何かあれば遠慮なく質問してください！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae25dc04c095084e91b1f2b0dfe81b87ca9c6d3934fc1ad15c6958801e08a15b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
